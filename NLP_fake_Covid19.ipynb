{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our aim is  to differentiate between true sources of covid news and fake covid news. We will try to do this by looking into several COVID-19 related titles to try to predict if they are true or false. In particular we are aiming at getting a good detector of reliable news (true).\n",
    "\n",
    "We will be given a multilingual dataset with COVID-19 related news, including some text elements, such as the original title (`source_title`), original body (`content_text`), and an English equivalent title (`title`). The dataset also includes a set of extra information that describes the language and countries of the story.\n",
    "\n",
    "Each row is labeled with a category that describes the reliability of the news piece. We want to predict two classes - true or false. However,  the dataset has a range of categories, not only these two. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier,EasyEnsembleClassifier\n",
    "\n",
    "from collections import Counter, OrderedDict\n",
    "from sklearn.base import TransformerMixin,BaseEstimator\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "import numpy as np\n",
    "import hashlib\n",
    "import math\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import string\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score,classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.decomposition import TruncatedSVD, PCA\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.svm import SVC\n",
    "import spacy\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from spacy.lang.en import English\n",
    "\n",
    "from pylab import barh,plot,yticks,show,grid,xlabel,figure,cla,close\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ". - matches any character, except newline.\n",
    "\n",
    "\\d, \\s \\S - match digit, match whitespace, not whitespace.\n",
    "\n",
    "\\b, \\B - word, not word boundary.\n",
    "\n",
    "[xyz] - matches x, y or z.\n",
    "\n",
    "[^xyz] - matches anything that is not x, y or z.\n",
    "\n",
    "[x-z] - matches a character between x and z.\n",
    "\n",
    "^xyz$ - ^ is the start of the string, $ is the end of the string.\n",
    "\n",
    "\\. - use escaping to match special characters.\n",
    "\n",
    "\\t, \\n - matches tab and newline.\n",
    "\n",
    "x* - matches 0 or more symbols x.\n",
    "\n",
    "x+ - matches 1 or more symbols x.\n",
    "\n",
    "x? - matches 0 or 1 symbol x.\n",
    "\n",
    ".?, *?, +?, etc - represent non-greedy search.\n",
    "\n",
    "x{5} - matches exactly 5 symbols x.\n",
    "\n",
    "x{5,} - matches 5 or more symbols x.\n",
    "\n",
    "x{5, 8} - matches between 5 and 8 symbols x.\n",
    "\n",
    "xy|yz - matches xy or yz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('stopwords')\n",
    "#stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "#stems = [list(map(stemmer.stem, words))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>American researcher Charles Lieber was arrest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Did Trump Blame Obama for ‘Bad’ COVID-19 Tests...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hundreds of sampoerna cigarette factory worke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dr. Megha Vyas from Pune died of COVID-19.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jacob Rothschild owns a patent to coronavirus.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0   American researcher Charles Lieber was arrest...\n",
       "1  Did Trump Blame Obama for ‘Bad’ COVID-19 Tests...\n",
       "2   Hundreds of sampoerna cigarette factory worke...\n",
       "3         Dr. Megha Vyas from Pune died of COVID-19.\n",
       "4     Jacob Rothschild owns a patent to coronavirus."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the dataset\n",
    "##there are two columns in the data set sentiment which is positive and negative and text columns this is movie review\n",
    "#df = pd.read_csv('./datasets/twitter.csv')\n",
    "df_train_nb = pd.read_csv('./data/covid19_data.csv')#, encoding='latin1')\n",
    "#df.drop([\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis=1,inplace=True)\n",
    "df_train_nb = df_train_nb[['class','title']]\n",
    "df_train_nb.rename(columns={\"class\":\"target\", \"title\":\"text\"},inplace=True)\n",
    "df_test= pd.read_csv('data/covid19_unlabelled_test.csv')\n",
    "\n",
    "df_test = df_test[['title']]\n",
    "df_test.rename(columns={\"title\":\"text\"},inplace=True)\n",
    "df_test.head()\n",
    "#NOTE: If the data set is so many choose part of that in order to accelerate the process of analysing\n",
    "    ##docs = df.text[:200]\n",
    "# Get the text\n",
    "#docs = df['text']\n",
    "\n",
    "\n",
    "\n",
    "###we can read from file and represent it as list as follows\n",
    "#def file_to_list(file_name):\n",
    "    #with open(file_name, 'r', encoding='utf-8') as f:\n",
    "        #return [line.strip() for line in f.readlines()]\n",
    "    \n",
    "#X_train_pre = file_to_list('data/tweets_train_preprocessed.txt')\n",
    "#X_dev_pre = file_to_list('data/tweets_dev_preprocessed.txt')\n",
    "#X_test_pre = file_to_list('data/tweets_test_preprocessed.txt')\n",
    "\n",
    "##############################################################Read a JSON file################################\n",
    "\n",
    "#docs = []\n",
    "#with open('./datasets/sample_data.json') as fp:\n",
    "    #for line in fp:\n",
    "        #entry = json.loads(line)\n",
    "        #docs.append(entry['body'])\n",
    "        \n",
    "#print('I read {} documents'.format(len(docs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['FALSE', 'False', 'Correct Attribution', 'True', 'Explanatory',\n",
       "       'false', 'Misleading', 'MISLEADING', 'Mostly True', 'No Evidence',\n",
       "       'partly false', 'Mostly false', 'Partly false', 'PARTLY FALSE',\n",
       "       'No evidence', 'Mostly False', 'misleading', 'Labeled Satire',\n",
       "       'News', 'Partly False', 'Misleading/False', 'Mixture',\n",
       "       'no evidence', 'MOSTLY FALSE', 'Misattributed', 'Unproven',\n",
       "       'Miscaptioned', 'Fake', 'Half True', 'PARTLY TRUE', 'Not true',\n",
       "       'Scam', \"(Org. doesn't apply rating)\", 'Partially false',\n",
       "       'MOSTLY TRUE', 'Partly true', 'mislEADING', 'NO EVIDENCE',\n",
       "       'half true', 'false and misleading', 'mostly false', nan,\n",
       "       'HALF TRUE', 'Two Pinocchios', 'Suspicions', 'Partly FALSE',\n",
       "       'PANTS ON FIRE', 'Correct', 'Misinformation / Conspiracy theory',\n",
       "       'IN DISPUTE', 'HALF TRUTH', 'MiSLEADING', 'Partially correct',\n",
       "       'Unlikely', 'Fake news', 'True but', 'Mostly true', 'Collections',\n",
       "       'Mixed', 'Unverified', 'Partially true'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_nb['target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A viral image suggests that cocaine kills cor...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Having sex every morning kills coronavirus.</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Picture shows the Mecca totally empty.</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Queen Elizabeth is shown in a quote card to b...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Official news: in Naples people have used Toc...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1755</th>\n",
       "      <td>Bill Gates patented the coronavirus.</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756</th>\n",
       "      <td>Vitamin D Supplements prevent health problems...</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1757</th>\n",
       "      <td>Smoking may protect against COVID-19; scienti...</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1758</th>\n",
       "      <td>Ibuprofen enhances the coronavirus.</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1759</th>\n",
       "      <td>Did genetic mutations cause the coronavirus t...</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1760 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text target\n",
       "0      A viral image suggests that cocaine kills cor...      f\n",
       "1           Having sex every morning kills coronavirus.      f\n",
       "2                Picture shows the Mecca totally empty.      f\n",
       "3      Queen Elizabeth is shown in a quote card to b...      f\n",
       "4      Official news: in Naples people have used Toc...      f\n",
       "...                                                 ...    ...\n",
       "1755               Bill Gates patented the coronavirus.      t\n",
       "1756   Vitamin D Supplements prevent health problems...      t\n",
       "1757   Smoking may protect against COVID-19; scienti...      t\n",
       "1758                Ibuprofen enhances the coronavirus.      t\n",
       "1759   Did genetic mutations cause the coronavirus t...      t\n",
       "\n",
       "[1760 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('./data/df_10percTrue_with_noevidence.csv')\n",
    "df_train.drop([\"Unnamed: 0\"], axis=1,inplace=True)\n",
    "df_train.rename(columns={\"label\":\"target\", \"title\":\"text\"},inplace=True)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "###function define to transform target column to true and false\n",
    "def clean_targ_col(df_):\n",
    "    df_['target'] = df_['target'].replace({'False' : 'false',\n",
    "    'FALSE' : 'false',\n",
    "    'Misleading' : 'false',\n",
    "    'MISLEADING' : 'false',\n",
    "    'Mostly false' : 'false',\n",
    "    'Partly false': 'false',\n",
    "    'misleading' : 'false',\n",
    "    'No evidence' : 'true',\n",
    "    'Mostly False' : 'false',\n",
    "    'Mixture': 'false',\n",
    "    'True': 'true',\n",
    "    'Explanatory': 'true',\n",
    "    'No Evidence': 'true',\n",
    "    'News': 'true',\n",
    "    'PARTLY FALSE': 'false',\n",
    "    'Unproven': 'false',\n",
    "    'MOSTLY FALSE': 'false',\n",
    "    'Partly False': 'false',\n",
    "    'Miscaptioned': 'false',\n",
    "    'partly false': 'false',\n",
    "    'mostly false' : 'false',\n",
    "    'Mostly True': 'true',\n",
    "    'MOSTLY TRUE': 'true',\n",
    "    'Misattributed': 'false',\n",
    "    \"(Org. doesn't apply rating)\": 'false',\n",
    "    'HALF TRUE': 'true',\n",
    "    'Correct Attribution' :'true',\n",
    "    'Partially false': 'false',\n",
    "    'Labeled Satire': 'false',\n",
    "    'Fake' : 'false',\n",
    "    'NO EVIDENCE': 'true',\n",
    "    'false' : 'false',\n",
    "    'Two Pinocchios': 'false',\n",
    "    'Scam' : 'false',\n",
    "    'no evidence': 'true',\n",
    "    'Half True': 'true',\n",
    "    'PARTLY TRUE': 'true',\n",
    "    'half true': 'true',\n",
    "    'Correct': 'true',\n",
    "    'mislEADING' : 'false',\n",
    "    'Suspicions': 'false',\n",
    "    'Not true' : 'false',\n",
    "    'nan': 'false',\n",
    "    'Partly FALSE': 'false',\n",
    "    'Misleading/False' : 'false',\n",
    "    'PANTS ON FIRE': 'false',\n",
    "    'Partially true': 'true',\n",
    "    'Mixed': 'false',\n",
    "    'IN DISPUTE': 'false',\n",
    "    'Unverified': 'false',\n",
    "    'HALF TRUTH': 'true',\n",
    "    'Collections': 'false',\n",
    "    'Partially correct': 'true',\n",
    "    'MiSLEADING' : 'false',\n",
    "    'Mostly true': 'true',\n",
    "    'True but': 'true',\n",
    "    'false and misleading' : 'false',\n",
    "    'Partly true': 'true',\n",
    "    'Misinformation / Conspiracy theory' : 'false',\n",
    "    'Unlikely' : 'false',\n",
    "    'Fake news' : 'false'})\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A viral image suggests that cocaine kills cor...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Having sex every morning kills coronavirus.</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Picture shows the Mecca totally empty.</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Queen Elizabeth is shown in a quote card to b...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Official news: in Naples people have used Toc...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1755</th>\n",
       "      <td>Bill Gates patented the coronavirus.</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756</th>\n",
       "      <td>Vitamin D Supplements prevent health problems...</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1757</th>\n",
       "      <td>Smoking may protect against COVID-19; scienti...</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1758</th>\n",
       "      <td>Ibuprofen enhances the coronavirus.</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1759</th>\n",
       "      <td>Did genetic mutations cause the coronavirus t...</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1760 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text target\n",
       "0      A viral image suggests that cocaine kills cor...      f\n",
       "1           Having sex every morning kills coronavirus.      f\n",
       "2                Picture shows the Mecca totally empty.      f\n",
       "3      Queen Elizabeth is shown in a quote card to b...      f\n",
       "4      Official news: in Naples people have used Toc...      f\n",
       "...                                                 ...    ...\n",
       "1755               Bill Gates patented the coronavirus.      t\n",
       "1756   Vitamin D Supplements prevent health problems...      t\n",
       "1757   Smoking may protect against COVID-19; scienti...      t\n",
       "1758                Ibuprofen enhances the coronavirus.      t\n",
       "1759   Did genetic mutations cause the coronavirus t...      t\n",
       "\n",
       "[1760 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_clean = clean_targ_col(df_train)\n",
    "df_train_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding the target coulmns to 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the labels\n",
    "#le = preprocessing.LabelEncoder()\n",
    "#le.fit(df_train_clean['target'].values)\n",
    "#df_train_clean['target'] = le.transform(df_train_clean['target'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A viral image suggests that cocaine kills cor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Having sex every morning kills coronavirus.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Picture shows the Mecca totally empty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Queen Elizabeth is shown in a quote card to b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Official news: in Naples people have used Toc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1755</th>\n",
       "      <td>Bill Gates patented the coronavirus.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756</th>\n",
       "      <td>Vitamin D Supplements prevent health problems...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1757</th>\n",
       "      <td>Smoking may protect against COVID-19; scienti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1758</th>\n",
       "      <td>Ibuprofen enhances the coronavirus.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1759</th>\n",
       "      <td>Did genetic mutations cause the coronavirus t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1760 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  target\n",
       "0      A viral image suggests that cocaine kills cor...       0\n",
       "1           Having sex every morning kills coronavirus.       0\n",
       "2                Picture shows the Mecca totally empty.       0\n",
       "3      Queen Elizabeth is shown in a quote card to b...       0\n",
       "4      Official news: in Naples people have used Toc...       0\n",
       "...                                                 ...     ...\n",
       "1755               Bill Gates patented the coronavirus.       1\n",
       "1756   Vitamin D Supplements prevent health problems...       1\n",
       "1757   Smoking may protect against COVID-19; scienti...       1\n",
       "1758                Ibuprofen enhances the coronavirus.       1\n",
       "1759   Did genetic mutations cause the coronavirus t...       1\n",
       "\n",
       "[1760 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_clean['target'] = df_train_clean['target'].replace({'f':0,'t':1})\n",
    "df_train_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No, a Hair Dryer Won’t Stop Coronavirus\\nA viral video that claims breathing hot air from a hair dryer could cure COVID-19 demonstrates a basic and dangerous lack of understanding about science.\\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\t\\tFalse'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_clean.text[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nc_train = df_train_clean.dropna().copy()\n",
    "df_nc_test = df_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split raw data without cleaning to train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split in train and validation\n",
    "train_nc_df, validation_nc_df = train_test_split(df_nc_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_nc_df.target.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom transformer to implement sentence cleaning\n",
    "class TextCleanerTransformer(TransformerMixin):\n",
    "    def __init__(self, tokenizer, stemmer, regex_list,\n",
    "                 lower=True, remove_punct=True):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.stemmer = stemmer\n",
    "        self.regex_list = regex_list\n",
    "        self.lower = lower\n",
    "        self.remove_punct = remove_punct\n",
    "        \n",
    "    def transform(self, X, *_):\n",
    "        X = list(map(self._clean_sentence, X))\n",
    "        return X\n",
    "    \n",
    "    def _clean_sentence(self, sentence):\n",
    "        \n",
    "        # Replace given regexes\n",
    "        for regex in self.regex_list:\n",
    "            sentence = re.sub(regex[0],regex[1], sentence)\n",
    "            \n",
    "        # lowercase\n",
    "        if self.lower:\n",
    "            sentence = sentence.lower()\n",
    "\n",
    "        # Split sentence into list of words\n",
    "        words = self.tokenizer.tokenize(sentence)\n",
    "            \n",
    "        # Remove punctuation\n",
    "        if self.remove_punct:\n",
    "            words = list(filter(lambda x: x not in string.punctuation, words))\n",
    "\n",
    "        # Stem words\n",
    "        if self.stemmer:\n",
    "            words = map(self.stemmer.stem, words)\n",
    "\n",
    "        # Join list elements into string\n",
    "        sentence = \" \".join(words)\n",
    "        \n",
    "        return sentence\n",
    "    \n",
    "    def fit(self, *_):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the data by function not class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = WordPunctTokenizer()\n",
    "\n",
    "def remove_html_tags(text):\n",
    "    soup = BeautifulSoup(text)\n",
    "    return soup.get_text()\n",
    "\n",
    "def remove_punct(text):\n",
    "    #remove everything except words, digits and space\n",
    "    text = re.sub(r'[^\\w\\s]','',text) \n",
    "        \n",
    "    #regex often miss the underscore so let's remove that as well\n",
    "    text = re.sub(r'\\_','',text)\n",
    "    text = text.lower()\n",
    "    \n",
    "    return text\n",
    "\n",
    "def remove_stopwords(text, stopwords):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [tok.lower() for tok in tokens]\n",
    "    if stopwords:\n",
    "        tokens = [tok for tok in tokens if tok not in stopwords]\n",
    "    tokens = [stemmer.stem(tok) for tok in tokens]\n",
    "\n",
    "    text_processed = ' '.join(tokens)\n",
    "    return text_processed\n",
    "\n",
    "\n",
    "\n",
    "def preprocessing_(df):\n",
    "    \"\"\"\n",
    "    Implement the three above functions in the respective order to remove html tags, punctuations and stopwords\n",
    "    Hint: Use the apply function.\n",
    "    \n",
    "    \"\"\"\n",
    "    df_ = df.copy()\n",
    "    \n",
    "    #df_['text'] = df_['text'].apply(...).apply(...).apply(...)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()\n",
    "    df_['text'] = df_['text'].apply(remove_html_tags).apply(remove_punct).apply(remove_stopwords,stopwords=en_stopwords)\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a tokenizer and a stemmer\n",
    "tokenizer = WordPunctTokenizer()\n",
    "stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "#regex_list = [(\"<[^>]*>\", \"\")]\n",
    "regex_list = [(\"\\#\",\"\")]\n",
    "#regex_list = [(\"\\\\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\t\\tFalse\",\"\")]\n",
    "\n",
    "#cleaner = TextCleanerTransformer(tokenizer, stemmer, regex_list)\n",
    "#docs = cleaner.transform(train_df.text.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am sonia  you are not .'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"I am sonia # you are not ##.\"\n",
    "for regex in regex_list:\n",
    "            sentence = re.sub(regex[0],regex[1], sentence)\n",
    "sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define pipline and predict MultinomialNB()(Did not work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build the pipeline\n",
    "#text_clf = Pipeline([('prep', TextCleanerTransformer(tokenizer, stemmer,regex_list)),\n",
    " #                  ('vect', CountVectorizer(stop_words='english', ngram_range=(1,2))),\n",
    "  #                 ('tfidf', TfidfTransformer()),\n",
    "   #                ('clf', MultinomialNB())])\n",
    "# Train the classifier\n",
    "##text_clf.fit(map(str, train_df['text'].values), train_df['sentiment'].values)\n",
    "#text_clf.fit(map(str, train_nc_df['text'].values), train_nc_df['target'].values)\n",
    "\n",
    "##predicted = text_clf.predict(map(str, validation_df['text'].values))\n",
    "##np.mean(predicted == validation_df['sentiment'])\n",
    "\n",
    "#predicted_val = text_clf.predict(map(str, validation_nc_df['text'].values))\n",
    "#np.mean(predicted_val == validation_nc_df['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define pipeline and predict RandomForrestcalssifier(I am not using this right now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5369318181818182"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the pipeline\n",
    "text_clf = Pipeline([('prep', TextCleanerTransformer(tokenizer, stemmer, regex_list)),\n",
    "                   ('vect', CountVectorizer(stop_words='english', ngram_range=(1,2))),\n",
    "                   ('tfidf', TfidfTransformer()),\n",
    "                   ('classifier', EasyEnsembleClassifier(n_estimators=10,random_state = 42))])\n",
    "# Train the classifier\n",
    "##text_clf.fit(map(str, train_df['text'].values), train_df['sentiment'].values)\n",
    "text_clf.fit(map(str, train_nc_df['text'].values), train_nc_df['target'].values)\n",
    "\n",
    "##predicted = text_clf.predict(map(str, validation_df['text'].values))\n",
    "##np.mean(predicted == validation_df['sentiment'])\n",
    "\n",
    "predicted_val = text_clf.predict(map(str, validation_nc_df['text'].values))\n",
    "np.mean(predicted_val == validation_nc_df['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check classification result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.51      0.66       315\n",
      "           1       0.16      0.78      0.26        37\n",
      "\n",
      "    accuracy                           0.54       352\n",
      "   macro avg       0.55      0.65      0.46       352\n",
      "weighted avg       0.87      0.54      0.62       352\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check the results\n",
    "##print(classification_report(y_dev, y_dev_pred))\n",
    "print(classification_report(validation_nc_df['target'].values,predicted_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_test = text_clf.predict(map(str, df_nc_test['text'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>American researcher Charles Lieber was arrest...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Did Trump Blame Obama for ‘Bad’ COVID-19 Tests...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hundreds of sampoerna cigarette factory worke...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dr. Megha Vyas from Pune died of COVID-19.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jacob Rothschild owns a patent to coronavirus.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2087</th>\n",
       "      <td>President Emmanuel Macron was cheered by a cr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2088</th>\n",
       "      <td>Five helicopters are going to spray the air w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2089</th>\n",
       "      <td>Coronavirus was created in a lab in order to ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2090</th>\n",
       "      <td>Video of a man dressed in white who recommend...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2091</th>\n",
       "      <td>President Donald Trump implemented “a travel ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2092 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  predicted\n",
       "0      American researcher Charles Lieber was arrest...          1\n",
       "1     Did Trump Blame Obama for ‘Bad’ COVID-19 Tests...          1\n",
       "2      Hundreds of sampoerna cigarette factory worke...          1\n",
       "3            Dr. Megha Vyas from Pune died of COVID-19.          1\n",
       "4        Jacob Rothschild owns a patent to coronavirus.          1\n",
       "...                                                 ...        ...\n",
       "2087   President Emmanuel Macron was cheered by a cr...          0\n",
       "2088   Five helicopters are going to spray the air w...          0\n",
       "2089   Coronavirus was created in a lab in order to ...          1\n",
       "2090   Video of a man dressed in white who recommend...          1\n",
       "2091   President Donald Trump implemented “a travel ...          1\n",
       "\n",
       "[2092 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nc_test['predicted'] = predicted_test\n",
    "df_nc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nc_test.predicted.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>American researcher Charles Lieber was arrest...</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Did Trump Blame Obama for ‘Bad’ COVID-19 Tests...</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hundreds of sampoerna cigarette factory worke...</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dr. Megha Vyas from Pune died of COVID-19.</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jacob Rothschild owns a patent to coronavirus.</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2087</th>\n",
       "      <td>President Emmanuel Macron was cheered by a cr...</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2088</th>\n",
       "      <td>Five helicopters are going to spray the air w...</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2089</th>\n",
       "      <td>Coronavirus was created in a lab in order to ...</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2090</th>\n",
       "      <td>Video of a man dressed in white who recommend...</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2091</th>\n",
       "      <td>President Donald Trump implemented “a travel ...</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2092 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text predicted\n",
       "0      American researcher Charles Lieber was arrest...      true\n",
       "1     Did Trump Blame Obama for ‘Bad’ COVID-19 Tests...      true\n",
       "2      Hundreds of sampoerna cigarette factory worke...      true\n",
       "3            Dr. Megha Vyas from Pune died of COVID-19.      true\n",
       "4        Jacob Rothschild owns a patent to coronavirus.      true\n",
       "...                                                 ...       ...\n",
       "2087   President Emmanuel Macron was cheered by a cr...     false\n",
       "2088   Five helicopters are going to spray the air w...     false\n",
       "2089   Coronavirus was created in a lab in order to ...      true\n",
       "2090   Video of a man dressed in white who recommend...      true\n",
       "2091   President Donald Trump implemented “a travel ...      true\n",
       "\n",
       "[2092 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nc_test['predicted']=df_nc_test['predicted'].replace({0:'false',1:'true'})\n",
    "df_nc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission file\n",
    "def create_submit(df):\n",
    "    df_out=pd.DataFrame()\n",
    "    df_out['class'] = df_nc_test['predicted']\n",
    "    return df_out\n",
    "submission = create_submit(df_nc_test)\n",
    "submission.to_csv(\"submission2.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export \n",
    "#su.to_csv('./data/submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to counts the number of occurrences of different tokens in a list and whole corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def build_vocabulary():\n",
    "    vocabulary = Counter()\n",
    "\n",
    "    for doc in docs:\n",
    "        words = doc.split()\n",
    "        vocabulary.update(words)\n",
    "    \n",
    "    return OrderedDict(vocabulary.most_common())\n",
    "# turn into a list of tuples and get the first 20 items\n",
    "list(build_vocabulary().items())[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Extraction from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are disabling the synctatic parser from pipeline to improve speed.\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser'])\n",
    "en_stopwords = nlp.Defaults.stop_words\n",
    "###################################################Clean data with the functions not classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_nb = pd.read_csv('./data/covid19_data.csv')#, encoding='latin1')\n",
    "#df.drop([\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis=1,inplace=True)\n",
    "###df_train_nb = df_train_nb[['class','title']]\n",
    "df_train_nb.rename(columns={\"class\":\"target\", \"title\":\"text\"},inplace=True)\n",
    "df_test= pd.read_csv('data/covid19_unlabelled_test.csv')\n",
    "\n",
    "#df_test = df_test[['title']]\n",
    "df_test.rename(columns={\"title\":\"text\"},inplace=True)\n",
    "#df_test.head()\n",
    "#NOTE: If the data set is so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5531, 25)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ad features before cleaning the data\n",
    "def Add_feature(df):\n",
    "    \"\"\"\n",
    "    Implement the three above functions in the respective order to remove html tags, punctuations and stopwords\n",
    "    Hint: Use the apply function.\n",
    "    \"\"\"\n",
    "    df_ = df.copy()\n",
    "\n",
    "    df_['length'] = df_['text'].map(len)# we test if this feature is ok or not by plotting in the next cell we can do it for all the new features if it is skew to right and left it is important otherwise not inmportant\n",
    "    df_['words'] = df_['text'].str.split().map(len)\n",
    "    stop_words = nltk.corpus.stopwords.words('english')\n",
    "#df_clean['words_not_stopword'] = df_clean['text'].apply(lambda x: len([t for t in x.split() if t not in stop_words]))\n",
    "#df_clean['commas'] = df_clean['text'].str.count(',')\n",
    "#df_clean['upper'] = df_clean['text'].map(lambda x: map(str.isupper, x)).map(sum)\n",
    "#df_clean['capitalized'] = df_clean['text'].map(lambda x: map(str.istitle, x)).map(sum)\n",
    "#get the average word length\n",
    "#df_clean['avg_word_length'] = df_clean['text'].apply(lambda x: np.mean([len(t) for t in x.split() if t not in stop_words]) if len([len(t) for t in x.split(' ') if t not in stop_words]) > 0 else 0)\n",
    "#number of adjective\n",
    "#df_clean['n_adjs'] = n_adjs\n",
    "#df_clean['positive_emojis_count'] = count_emoji_matches(pos_patterns)\n",
    "#df_clean['negative_emojis_count'] = count_emoji_matches(neg_patterns)\n",
    "    df_['hasTitle'] = 0\n",
    "    df_.loc[df_['source_title'].isna(),'hasTitle'] = 1\n",
    "    df_['hasContent'] = 0\n",
    "    df_.loc[df_['content_text'].isna(),'hasContent'] = 1\n",
    "    df_['hasLang'] = 0\n",
    "    df_.loc[df.lang.isna(),'hasLang'] = 1\n",
    "    df_['hasCountry1'] = 0\n",
    "    df_.loc[~df.lang.isna(),'hasCountry1'] = 1\n",
    "    df_['hasCountry2'] = 0\n",
    "    df_.loc[~df.lang.isna(),'hasCountry2'] = 1\n",
    "    df_['hasCountry3'] = 0\n",
    "    df_.loc[~df.lang.isna(),'hasCountry3'] = 1\n",
    "    df_['hasCountry4'] = 0\n",
    "    df_.loc[~df.lang.isna(),'hasCountry4'] = 1\n",
    "    df_['num_countries'] = df_['hasCountry1']+df_['hasCountry2']+df_['hasCountry3']+df_['hasCountry4']\n",
    "    return df_\n",
    "\n",
    "df_nc_train = Add_feature(df_train_nb)\n",
    "df_nc_test= Add_feature(df_test)\n",
    "\n",
    "df_nc_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = preprocessing_(df_nc_train)\n",
    "df_clean_test=preprocessing_(df_nc_test)\n",
    "\n",
    "# define docs as a list of sentences\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['verifiedby', 'country', 'target', 'text', 'published_date', 'country1',\n",
       "       'country2', 'country3', 'country4', 'article_source', 'ref_source',\n",
       "       'source_title', 'content_text', 'category', 'lang', 'length', 'words',\n",
       "       'hasTitle', 'hasContent', 'hasLang', 'hasCountry1', 'hasCountry2',\n",
       "       'hasCountry3', 'hasCountry4', 'num_countries'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_prep(df_):    \n",
    "    df_.drop(['verifiedby', 'country', 'published_date', 'country1',\n",
    "       'country2', 'country3', 'country4', 'article_source', 'ref_source',\n",
    "       'source_title', 'content_text', 'category', 'lang'], axis=1,inplace=True)\n",
    "    return df_\n",
    "df_clean = func_prep(df_clean)\n",
    "df_clean_test = func_prep(df_clean_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5531, 12)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## correcting the target column \n",
    "df_clean = clean_targ_col(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding the target columns\n",
    "df_clean['target'] = df_clean['target'].replace({'false':0,'true':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_csv(\"df_cleanbefore10.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "! explorer.exe ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = pd.read_csv('./data/df_10percTrue_newfeatures_v2.csv')#, encoding='latin1')df_10percTrue_newfeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "      <th>words</th>\n",
       "      <th>hasTitle</th>\n",
       "      <th>hasContent</th>\n",
       "      <th>hasLang</th>\n",
       "      <th>hasCountry1</th>\n",
       "      <th>hasCountry2</th>\n",
       "      <th>hasCountry3</th>\n",
       "      <th>hasCountry4</th>\n",
       "      <th>num_countries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>african union au valid covidorgan malagasi rem...</td>\n",
       "      <td>108</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>video muslim fruitvendor spit fruit spread cor...</td>\n",
       "      <td>75</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>video show alleg hotel owner new york jump win...</td>\n",
       "      <td>164</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>post claim presid donald trump announc roch di...</td>\n",
       "      <td>110</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>imag medic facil share claim indian armi set 1...</td>\n",
       "      <td>148</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text  length  words  \\\n",
       "0     0.0  african union au valid covidorgan malagasi rem...     108     14   \n",
       "1     0.0  video muslim fruitvendor spit fruit spread cor...      75     12   \n",
       "2     0.0  video show alleg hotel owner new york jump win...     164     29   \n",
       "3     0.0  post claim presid donald trump announc roch di...     110     16   \n",
       "4     0.0  imag medic facil share claim indian armi set 1...     148     24   \n",
       "\n",
       "   hasTitle  hasContent  hasLang  hasCountry1  hasCountry2  hasCountry3  \\\n",
       "0         0           0        0            1            1            1   \n",
       "1         0           0        0            1            1            1   \n",
       "2         0           0        0            1            1            1   \n",
       "3         0           0        0            1            1            1   \n",
       "4         0           0        0            1            1            1   \n",
       "\n",
       "   hasCountry4  num_countries  \n",
       "0            1              4  \n",
       "1            1              4  \n",
       "2            1              4  \n",
       "3            1              4  \n",
       "4            1              4  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = list(df_clean.text.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are going to use the function pipe to process all documents.\n",
    "# One of the strenghts for SpaCy is the parallel processing using all your computer cores.\n",
    "# In this step, SpaCy performs the NLP pipeline for all the docs, so it may take a while\n",
    "\n",
    "docs = list(nlp.pipe(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#docs[0].ents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Matcher ans pass vocabulary to it\n",
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab) # Pass the vocabulary object to Matcher.__init__()\n",
    "pattern = [{'POS': 'ADV'},{'POS':'ADJ'}]\n",
    "matcher.add('word',None,pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Extracting adjectives,\n",
    "for i, doc in enumerate(docs[:400]):\n",
    "    #print(i,doc)\n",
    "    matches = matcher(doc)\n",
    "    for match_id, start, end in matches:\n",
    "        span = doc[start:end]  # the matched span\n",
    "        print(i, start, end, span)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i, doc in enumerate(docs[:400]):\n",
    "    for e in doc.ents:\n",
    "        if e.label_ == 'GPE':   \n",
    "            print(i, e.text, e.start_char, e.end_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "#\n",
    "pattern = [{'ENT_TYPE':'GPE'}]\n",
    "matcher.add('LOC', None, pattern)\n",
    "#matcher.add(...)\n",
    "most_common_ents_list = []\n",
    "for doc in docs:\n",
    "    matches = matcher(doc)\n",
    "    for match_id, start, end in matches:\n",
    "        span = doc[start:end]  # the matched span\n",
    "        span_text = span.text  # the span as a string\n",
    "        most_common_ents_list.append(span_text)\n",
    "most_common_ents = Counter(most_common_ents_list).most_common(10)\n",
    "most_common_ents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is this feature usefull?(by the plot the length is  useful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 300)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#length column\n",
    "ax_list = df_clean.hist(column='length', by='target', bins=50,figsize=(12,4))\n",
    "ax_list[0].set_xlim((0,300))\n",
    "ax_list[1].set_xlim((0,300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 300)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax_list = df_clean.hist(column='words', by='target', bins=50,figsize=(12,4))\n",
    "ax_list[0].set_xlim((0,300))\n",
    "ax_list[1].set_xlim((0,300))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class for choosing extra features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Selector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a column from the dataframe to perform additional transformations on\n",
    "    \"\"\" \n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "\n",
    "class TextSelector(Selector):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on text columns in the data\n",
    "    \"\"\"\n",
    "    def transform(self, X):\n",
    "        return X[self.key]\n",
    "    \n",
    "    \n",
    "class NumberSelector(Selector):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on numeric columns in the data\n",
    "    \"\"\"\n",
    "    def transform(self, X):\n",
    "        return X[[self.key]]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['target', 'text', 'length', 'words', 'hasTitle', 'hasContent',\n",
       "       'hasLang', 'hasCountry1', 'hasCountry2', 'hasCountry3', 'hasCountry4',\n",
       "       'num_countries'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text = Pipeline([\n",
    "                ('selector', TextSelector(\"text\")),\n",
    "                ('tfidf', TfidfVectorizer())\n",
    "            ])\n",
    "\n",
    "length =  Pipeline([\n",
    "                ('selector', NumberSelector(\"length\")),\n",
    "                ('standard', StandardScaler())\n",
    "            ])\n",
    "\n",
    "words =  Pipeline([\n",
    "                ('selector', NumberSelector(key='words')),\n",
    "                ('standard', StandardScaler())\n",
    "            ])\n",
    "\n",
    "        \n",
    "hasTitle =  Pipeline([\n",
    "                ('selector', NumberSelector(key='hasTitle')),\n",
    "                ('standard', StandardScaler())\n",
    "            ])\n",
    "\n",
    "hasContent =  Pipeline([\n",
    "                ('selector', NumberSelector(key='hasContent')),\n",
    "                ('standard', StandardScaler()),\n",
    "            ])\n",
    "hasLang =  Pipeline([\n",
    "                ('selector', NumberSelector(key='hasLang')),\n",
    "                ('standard', StandardScaler()),\n",
    "            ])\n",
    "hasCountry1 =  Pipeline([\n",
    "                ('selector', NumberSelector(key='hasCountry1')),\n",
    "                ('standard', StandardScaler()),\n",
    "            ])\n",
    "\n",
    "hasCountry2 =  Pipeline([\n",
    "                ('selector', NumberSelector(key='hasCountry2')),\n",
    "                ('standard', StandardScaler()),\n",
    "            ])\n",
    "hasCountry3 =  Pipeline([\n",
    "                ('selector', NumberSelector(key='hasCountry3')),\n",
    "                ('standard', StandardScaler()),\n",
    "            ])\n",
    "hasCountry4 =  Pipeline([\n",
    "                ('selector', NumberSelector(key='hasCountry4')),\n",
    "                ('standard', StandardScaler()),\n",
    "            ])\n",
    "num_countries =  Pipeline([\n",
    "                ('selector', NumberSelector(key='num_countries')),\n",
    "                ('standard', StandardScaler()),\n",
    "            ])\n",
    "\n",
    "   \n",
    "feats = FeatureUnion([('text', text), \n",
    "                      ('length', length),\n",
    "                      ('words', words),\n",
    "                      ('hasTitle', hasTitle),\n",
    "                      #('avg_word_length', avg_word_length),\n",
    "                      ('hasContent', hasContent),\n",
    "                     ('hasLang', hasLang),\n",
    "                     ('hasCountry1', hasCountry1),\n",
    "                     #('n_adjs',n_adjs),\n",
    "                      ('hasCountry2',hasCountry2),\n",
    "                      ('hasCountry3',hasCountry3),\n",
    "                      ('hasCountry4',hasCountry4),\n",
    "                      ('num_countries',num_countries),\n",
    "                     ])\n",
    "\n",
    "feature_processing = Pipeline([('feats', feats)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_clean = df_clean.reset_index(drop = True)\n",
    "#df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split train and test of clean data and fitting the model and predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split in train and validation\n",
    "train_cl_data, val_cl_data = train_test_split(df_clean, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target           0\n",
       "text             0\n",
       "length           0\n",
       "words            0\n",
       "hasTitle         0\n",
       "hasContent       0\n",
       "hasLang          0\n",
       "hasCountry1      0\n",
       "hasCountry2      0\n",
       "hasCountry3      0\n",
       "hasCountry4      0\n",
       "num_countries    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cl_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target           0\n",
       "text             0\n",
       "length           0\n",
       "words            0\n",
       "hasTitle         0\n",
       "hasContent       0\n",
       "hasLang          0\n",
       "hasCountry1      0\n",
       "hasCountry2      0\n",
       "hasCountry3      0\n",
       "hasCountry4      0\n",
       "num_countries    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cl_data = train_cl_data.dropna()\n",
    "train_cl_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6221590909090909"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('features',feats),\n",
    "    ('classifier', EasyEnsembleClassifier(n_estimators=10,random_state = 42)),\n",
    "    #('classifier', LinearRegression()),\n",
    "])\n",
    "\n",
    "pipeline.fit(train_cl_data, train_cl_data.target)\n",
    "\n",
    "preds_val = pipeline.predict(val_cl_data)\n",
    "np.mean(preds_val == val_cl_data.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check classification results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.62      0.75       315\n",
      "         1.0       0.17      0.65      0.27        37\n",
      "\n",
      "    accuracy                           0.62       352\n",
      "   macro avg       0.55      0.63      0.51       352\n",
      "weighted avg       0.86      0.62      0.70       352\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check the results\n",
    "##print(classification_report(y_dev, y_dev_pred))\n",
    "print(classification_report(val_cl_data['target'].values,preds_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "      <th>words</th>\n",
       "      <th>hasTitle</th>\n",
       "      <th>hasContent</th>\n",
       "      <th>hasLang</th>\n",
       "      <th>hasCountry1</th>\n",
       "      <th>hasCountry2</th>\n",
       "      <th>hasCountry3</th>\n",
       "      <th>hasCountry4</th>\n",
       "      <th>num_countries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>0.0</td>\n",
       "      <td>lysol disinfect coronavirus show virus new</td>\n",
       "      <td>72</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>0.0</td>\n",
       "      <td>book name ahbarüz zaman predict coronavirus ep...</td>\n",
       "      <td>72</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1683</th>\n",
       "      <td>1.0</td>\n",
       "      <td>vibrat includ come emot kill new coronavirus</td>\n",
       "      <td>80</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>0.0</td>\n",
       "      <td>video show social distanc follow delhi</td>\n",
       "      <td>67</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>0.0</td>\n",
       "      <td>reach lung coronavirus remain throat day time ...</td>\n",
       "      <td>258</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>0.0</td>\n",
       "      <td>boil weed ginger covid19 victim virus vanish</td>\n",
       "      <td>70</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>0.0</td>\n",
       "      <td>media group globo publish photo dead lampedusa...</td>\n",
       "      <td>113</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>0.0</td>\n",
       "      <td>african resist covid19</td>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1654</th>\n",
       "      <td>1.0</td>\n",
       "      <td>neem leaf malaria effici covid19</td>\n",
       "      <td>70</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>0.0</td>\n",
       "      <td>kabataan repres philippin sarah elago test pos...</td>\n",
       "      <td>89</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>352 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      target                                               text  length  \\\n",
       "1125     0.0         lysol disinfect coronavirus show virus new      72   \n",
       "1030     0.0  book name ahbarüz zaman predict coronavirus ep...      72   \n",
       "1683     1.0       vibrat includ come emot kill new coronavirus      80   \n",
       "1541     0.0             video show social distanc follow delhi      67   \n",
       "344      0.0  reach lung coronavirus remain throat day time ...     258   \n",
       "...      ...                                                ...     ...   \n",
       "494      0.0       boil weed ginger covid19 victim virus vanish      70   \n",
       "1050     0.0  media group globo publish photo dead lampedusa...     113   \n",
       "1544     0.0                             african resist covid19      41   \n",
       "1654     1.0                   neem leaf malaria effici covid19      70   \n",
       "381      0.0  kabataan repres philippin sarah elago test pos...      89   \n",
       "\n",
       "      words  hasTitle  hasContent  hasLang  hasCountry1  hasCountry2  \\\n",
       "1125     11         0           0        0            1            1   \n",
       "1030      9         0           1        0            1            1   \n",
       "1683     11         0           0        0            1            1   \n",
       "1541     11         0           0        0            1            1   \n",
       "344      50         0           0        0            1            1   \n",
       "...     ...       ...         ...      ...          ...          ...   \n",
       "494      12         0           0        0            1            1   \n",
       "1050     20         0           0        0            1            1   \n",
       "1544      6         0           0        0            1            1   \n",
       "1654     10         0           0        0            1            1   \n",
       "381      11         0           0        0            1            1   \n",
       "\n",
       "      hasCountry3  hasCountry4  num_countries  \n",
       "1125            1            1              4  \n",
       "1030            1            1              4  \n",
       "1683            1            1              4  \n",
       "1541            1            1              4  \n",
       "344             1            1              4  \n",
       "...           ...          ...            ...  \n",
       "494             1            1              4  \n",
       "1050            1            1              4  \n",
       "1544            1            1              4  \n",
       "1654            1            1              4  \n",
       "381             1            1              4  \n",
       "\n",
       "[352 rows x 12 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_cl_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test prediction\n",
    "preds_test = pipeline.predict(df_clean_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "      <th>words</th>\n",
       "      <th>hasTitle</th>\n",
       "      <th>hasContent</th>\n",
       "      <th>hasLang</th>\n",
       "      <th>hasCountry1</th>\n",
       "      <th>hasCountry2</th>\n",
       "      <th>hasCountry3</th>\n",
       "      <th>hasCountry4</th>\n",
       "      <th>num_countries</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>american research charl lieber arrest sell nov...</td>\n",
       "      <td>98</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trump blame obama bad covid19 test wasnt time ...</td>\n",
       "      <td>242</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hundr sampoerna cigarett factori worker covid19</td>\n",
       "      <td>63</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dr megha vya pune die covid19</td>\n",
       "      <td>43</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jacob rothschild own patent coronavirus</td>\n",
       "      <td>47</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2087</th>\n",
       "      <td>presid emmanuel macron cheer crowd fake suppor...</td>\n",
       "      <td>102</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2088</th>\n",
       "      <td>helicopt go spray air disinfect overnight orde...</td>\n",
       "      <td>111</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2089</th>\n",
       "      <td>coronavirus creat lab order destroy chines eco...</td>\n",
       "      <td>106</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2090</th>\n",
       "      <td>video man dress white recommend take ivermecti...</td>\n",
       "      <td>151</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2091</th>\n",
       "      <td>presid donald trump implement travel ban didnt...</td>\n",
       "      <td>155</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2092 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  length  words  \\\n",
       "0     american research charl lieber arrest sell nov...      98     14   \n",
       "1     trump blame obama bad covid19 test wasnt time ...     242     34   \n",
       "2       hundr sampoerna cigarett factori worker covid19      63      8   \n",
       "3                         dr megha vya pune die covid19      43      8   \n",
       "4               jacob rothschild own patent coronavirus      47      7   \n",
       "...                                                 ...     ...    ...   \n",
       "2087  presid emmanuel macron cheer crowd fake suppor...     102     17   \n",
       "2088  helicopt go spray air disinfect overnight orde...     111     18   \n",
       "2089  coronavirus creat lab order destroy chines eco...     106     18   \n",
       "2090  video man dress white recommend take ivermecti...     151     24   \n",
       "2091  presid donald trump implement travel ban didnt...     155     24   \n",
       "\n",
       "      hasTitle  hasContent  hasLang  hasCountry1  hasCountry2  hasCountry3  \\\n",
       "0            0           0        0            1            1            1   \n",
       "1            0           0        0            1            1            1   \n",
       "2            0           0        0            1            1            1   \n",
       "3            0           0        0            1            1            1   \n",
       "4            1           1        0            1            1            1   \n",
       "...        ...         ...      ...          ...          ...          ...   \n",
       "2087         0           0        0            1            1            1   \n",
       "2088         1           1        0            1            1            1   \n",
       "2089         0           0        0            1            1            1   \n",
       "2090         0           0        0            1            1            1   \n",
       "2091         0           0        0            1            1            1   \n",
       "\n",
       "      hasCountry4  num_countries  predicted  \n",
       "0               1              4        0.0  \n",
       "1               1              4        1.0  \n",
       "2               1              4        0.0  \n",
       "3               1              4        1.0  \n",
       "4               1              4        1.0  \n",
       "...           ...            ...        ...  \n",
       "2087            1              4        0.0  \n",
       "2088            1              4        1.0  \n",
       "2089            1              4        0.0  \n",
       "2090            1              4        0.0  \n",
       "2091            1              4        1.0  \n",
       "\n",
       "[2092 rows x 12 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean_test['predicted'] = preds_test\n",
    "df_clean_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "      <th>words</th>\n",
       "      <th>hasTitle</th>\n",
       "      <th>hasContent</th>\n",
       "      <th>hasLang</th>\n",
       "      <th>hasCountry1</th>\n",
       "      <th>hasCountry2</th>\n",
       "      <th>hasCountry3</th>\n",
       "      <th>hasCountry4</th>\n",
       "      <th>num_countries</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>american research charl lieber arrest sell nov...</td>\n",
       "      <td>98</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trump blame obama bad covid19 test wasnt time ...</td>\n",
       "      <td>242</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hundr sampoerna cigarett factori worker covid19</td>\n",
       "      <td>63</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dr megha vya pune die covid19</td>\n",
       "      <td>43</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jacob rothschild own patent coronavirus</td>\n",
       "      <td>47</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2087</th>\n",
       "      <td>presid emmanuel macron cheer crowd fake suppor...</td>\n",
       "      <td>102</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2088</th>\n",
       "      <td>helicopt go spray air disinfect overnight orde...</td>\n",
       "      <td>111</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2089</th>\n",
       "      <td>coronavirus creat lab order destroy chines eco...</td>\n",
       "      <td>106</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2090</th>\n",
       "      <td>video man dress white recommend take ivermecti...</td>\n",
       "      <td>151</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2091</th>\n",
       "      <td>presid donald trump implement travel ban didnt...</td>\n",
       "      <td>155</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2092 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  length  words  \\\n",
       "0     american research charl lieber arrest sell nov...      98     14   \n",
       "1     trump blame obama bad covid19 test wasnt time ...     242     34   \n",
       "2       hundr sampoerna cigarett factori worker covid19      63      8   \n",
       "3                         dr megha vya pune die covid19      43      8   \n",
       "4               jacob rothschild own patent coronavirus      47      7   \n",
       "...                                                 ...     ...    ...   \n",
       "2087  presid emmanuel macron cheer crowd fake suppor...     102     17   \n",
       "2088  helicopt go spray air disinfect overnight orde...     111     18   \n",
       "2089  coronavirus creat lab order destroy chines eco...     106     18   \n",
       "2090  video man dress white recommend take ivermecti...     151     24   \n",
       "2091  presid donald trump implement travel ban didnt...     155     24   \n",
       "\n",
       "      hasTitle  hasContent  hasLang  hasCountry1  hasCountry2  hasCountry3  \\\n",
       "0            0           0        0            1            1            1   \n",
       "1            0           0        0            1            1            1   \n",
       "2            0           0        0            1            1            1   \n",
       "3            0           0        0            1            1            1   \n",
       "4            1           1        0            1            1            1   \n",
       "...        ...         ...      ...          ...          ...          ...   \n",
       "2087         0           0        0            1            1            1   \n",
       "2088         1           1        0            1            1            1   \n",
       "2089         0           0        0            1            1            1   \n",
       "2090         0           0        0            1            1            1   \n",
       "2091         0           0        0            1            1            1   \n",
       "\n",
       "      hasCountry4  num_countries predicted  \n",
       "0               1              4     false  \n",
       "1               1              4      true  \n",
       "2               1              4     false  \n",
       "3               1              4      true  \n",
       "4               1              4      true  \n",
       "...           ...            ...       ...  \n",
       "2087            1              4     false  \n",
       "2088            1              4      true  \n",
       "2089            1              4     false  \n",
       "2090            1              4     false  \n",
       "2091            1              4      true  \n",
       "\n",
       "[2092 rows x 12 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean_test['predicted']=df_clean_test['predicted'].replace({0:'false',1:'true'})\n",
    "df_clean_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission file\n",
    "def create_submit(df):\n",
    "    df_out=pd.DataFrame()\n",
    "    df_out['class'] = df['predicted']\n",
    "    return df_out\n",
    "submission = create_submit(df_clean_test)\n",
    "submission.to_csv(\"submission3.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to reduce the features and choose the more important one\n",
    "1- Feature Selection from chi-squared\n",
    "2-Feature selection with SVD and PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # The following will plot the  most dependent features from the chi-squared values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download(\"stopwords\") \n",
    "#stopword_list =list(nltk.corpus.stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess to run the following cell about chi_values\n",
    "#df is already clean data\n",
    "#Encode the lables y_train and y_dev\n",
    "#vec = TfidfVectorizer(ngram_range=(1,2))\n",
    "#X_train_vec = vec.fit_transform(train_cl_data.text)\n",
    "#X_test_vec = vec.transform(test_cl_data.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chi_values, p_values = chi2(X_train_vec, train_cl_data.target.values)\n",
    "#print(chi_values, p_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_names = vec.get_feature_names()\n",
    "\n",
    "#cla()   # Clear axis\n",
    "#close() # Close a figure window\n",
    "\n",
    "#figure(figsize=(12,10))\n",
    "#zipped_chi_squared = zip(feature_names, chi_values)\n",
    "#sorted_chi_values = sorted(zipped_chi_squared, key=lambda x:x[1]) \n",
    "#top_chi_values = list(zip(*sorted_chi_values[-30:]))\n",
    "\n",
    "#x = range(len(top_chi_values[1]))\n",
    "#labels = top_chi_values[0]\n",
    "#barh(x, list(top_chi_values)[1], align='center', alpha=.2, color='g')\n",
    "#yticks(x, labels)\n",
    "#xlabel('$\\chi^2$')\n",
    "#show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch2 choose best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ch2 = SelectKBest(chi2, k=10)\n",
    "#ch2.fit(X_train_vec, train_cl_data.target)\n",
    "\n",
    "#most_important_features = [feature_names[i] for i in ch2.get_support(indices=True)]\n",
    "#for f in most_important_features:\n",
    " #   print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_chi = ch2.transform(X_train_vec)\n",
    "#X_test_chi = ch2.transform(X_test_vec)\n",
    "\n",
    "#clf = MultinomialNB()\n",
    "#%timeit clf.fit(X_train_chi, train_cl_data.target)\n",
    "\n",
    "#y_pred = clf.predict(X_test_chi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
